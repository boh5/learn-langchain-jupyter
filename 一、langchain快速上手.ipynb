{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables from .env file (requires `python-dotenv`)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我是中文聊天机器人。很高兴与你交流。有什么问题或话题想要讨论吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 37, 'total_tokens': 67, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.213986658, 'prompt_time': 0.00178822, 'completion_time': 0.068573783, 'total_time': 0.070362003}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_0f5c9bc037', 'id': 'chatcmpl-0236c18b-fcac-4140-8e6f-97dc652b2b0b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--dd86c40a-c095-4540-a2ad-a3ae77e7f928-0', usage_metadata={'input_tokens': 37, 'output_tokens': 30, 'total_tokens': 67, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    model_provider=\"openai\",\n",
    "    temperature=0,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    ")\n",
    "\n",
    "model.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，我很好，谢谢。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 49, 'total_tokens': 59, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.219160079, 'prompt_time': 0.002789089, 'completion_time': 0.029778922, 'total_time': 0.032568011}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_0f5c9bc037', 'id': 'chatcmpl-6dafc92b-ee5a-4fb7-944d-c2af40d18284', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--febdfd3f-bab4-4969-b2e7-4c3d900e860e-0', usage_metadata={'input_tokens': 49, 'output_tokens': 10, 'total_tokens': 59, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Chinese.\"),\n",
    "    HumanMessage(\"Hi, how are you?\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，有什么可以帮你的吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 37, 'total_tokens': 47, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.220046061, 'prompt_time': 0.001840277, 'completion_time': 0.047007125, 'total_time': 0.048847402}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'id': 'chatcmpl-a9315665-e462-40e6-9e04-2f6cb5e370f6', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--d47c53dd-038a-4612-8e1e-956b0f16552e-0', usage_metadata={'input_tokens': 37, 'output_tokens': 10, 'total_tokens': 47, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "llm.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "我\n",
      "是\n",
      "人\n",
      "工\n",
      "智能\n",
      "语言\n",
      "模型\n",
      "，我\n",
      "在\n",
      "这里\n",
      "帮助\n",
      "您\n",
      "解决\n",
      "广\n",
      "泛\n",
      "的问题\n",
      "和\n",
      "任务\n",
      "。\n",
      "以下\n",
      "是一\n",
      "些\n",
      "我\n",
      "可以\n",
      "帮助\n",
      "您的\n",
      "例\n",
      "子\n",
      "：\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      " **\n",
      "回答\n",
      "问题\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "提供\n",
      "来自\n",
      "各\n",
      "个\n",
      "领域\n",
      "的\n",
      "信息\n",
      "，\n",
      "包括\n",
      "历史\n",
      "、\n",
      "科学\n",
      "、\n",
      "技术\n",
      "、\n",
      "娱乐\n",
      "等\n",
      "。\n",
      "\n",
      "2\n",
      ".\n",
      " **\n",
      "语言\n",
      "翻\n",
      "译\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "将\n",
      "文\n",
      "本\n",
      "从\n",
      "一种\n",
      "语言\n",
      "翻\n",
      "译\n",
      "成\n",
      "另\n",
      "一种\n",
      "语言\n",
      "，\n",
      "包括\n",
      "流\n",
      "行\n",
      "语言\n",
      "如\n",
      "西\n",
      "班\n",
      "牙\n",
      "语\n",
      "、\n",
      "法\n",
      "语\n",
      "、\n",
      "德\n",
      "语\n",
      "、\n",
      "中文\n",
      "等\n",
      "。\n",
      "\n",
      "3\n",
      ".\n",
      " **\n",
      "写\n",
      "作\n",
      "和\n",
      "编辑\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "帮助\n",
      "您\n",
      "生成\n",
      "文\n",
      "本\n",
      "、\n",
      "校\n",
      "对\n",
      "和\n",
      "编辑\n",
      "您的\n",
      "写\n",
      "作\n",
      "，\n",
      "包括\n",
      "文章\n",
      "、\n",
      "电子\n",
      "邮\n",
      "件\n",
      "和\n",
      "报告\n",
      "。\n",
      "\n",
      "4\n",
      ".\n",
      " **\n",
      "数学\n",
      "和\n",
      "计算\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "帮助\n",
      "您\n",
      "解决\n",
      "数学\n",
      "问题\n",
      "，\n",
      "包括\n",
      "代\n",
      "数\n",
      "、\n",
      "几\n",
      "何\n",
      "、\n",
      "微\n",
      "积\n",
      "分\n",
      "和\n",
      "统计\n",
      "。\n",
      "\n",
      "5\n",
      ".\n",
      " **\n",
      "对\n",
      "话\n",
      "和\n",
      "聊\n",
      "天\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "参与\n",
      "对\n",
      "话\n",
      "，\n",
      "回答\n",
      "问题\n",
      "，并\n",
      "就\n",
      "各种\n",
      "话\n",
      "题\n",
      "进行\n",
      "讨\n",
      "论\n",
      "。\n",
      "\n",
      "6\n",
      ".\n",
      " **\n",
      "生成\n",
      "文\n",
      "本\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "创建\n",
      "文\n",
      "本\n",
      "，\n",
      "包括\n",
      "故事\n",
      "、\n",
      "诗\n",
      "歌\n",
      "和\n",
      "对\n",
      "话\n",
      "。\n",
      "\n",
      "7\n",
      ".\n",
      " **\n",
      "总\n",
      "结\n",
      "和\n",
      "摘要\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "总\n",
      "结\n",
      "长\n",
      "篇\n",
      "文\n",
      "档\n",
      "、\n",
      "文章\n",
      "和\n",
      "网\n",
      "页\n",
      "，\n",
      "突\n",
      "出\n",
      "关键\n",
      "点\n",
      "和\n",
      "主要\n",
      "思想\n",
      "。\n",
      "\n",
      "8\n",
      ".\n",
      " **\n",
      "帮助\n",
      "写\n",
      "作\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "帮助\n",
      "您\n",
      "生成\n",
      "想\n",
      "法\n",
      "、\n",
      "头\n",
      "条\n",
      "和\n",
      "标题\n",
      "，并\n",
      "提供\n",
      "写\n",
      "作\n",
      "技\n",
      "巧\n",
      "和\n",
      "建议\n",
      "。\n",
      "\n",
      "9\n",
      ".\n",
      " **\n",
      "学习\n",
      "和\n",
      "教育\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "帮助\n",
      "您\n",
      "学习\n",
      "新\n",
      "概念\n",
      "、\n",
      "准备\n",
      "考试\n",
      "，并\n",
      "提供\n",
      "教育\n",
      "资源\n",
      "和\n",
      "材料\n",
      "。\n",
      "\n",
      "10\n",
      ".\n",
      " **\n",
      "娱乐\n",
      "**\n",
      "：\n",
      "我\n",
      "可以\n",
      "参与\n",
      "游戏\n",
      "、\n",
      "谜\n",
      "题\n",
      "和\n",
      "有\n",
      "趣\n",
      "的\n",
      "活动\n",
      "，\n",
      "例如\n",
      "“\n",
      "你\n",
      "更\n",
      "喜欢\n",
      "什么\n",
      "”\n",
      "和\n",
      "“\n",
      "两\n",
      "真\n",
      "一\n",
      "假\n",
      "”。\n",
      "\n",
      "\n",
      "您\n",
      "可以\n",
      "问\n",
      "我\n",
      "任何\n",
      "问题\n",
      "，\n",
      "讨\n",
      "论\n",
      "任何\n",
      "话\n",
      "题\n",
      "，\n",
      "或者\n",
      "要求\n",
      "我\n",
      "帮助\n",
      "完成\n",
      "特\n",
      "定\n",
      "任务\n",
      "。我\n",
      "会\n",
      "尽\n",
      "力\n",
      "提供\n",
      "有\n",
      "帮助\n",
      "和\n",
      "准\n",
      "确\n",
      "的\n",
      "回\n",
      "应\n",
      "。\n",
      "\n",
      "\n",
      "你\n",
      "今天\n",
      "需要\n",
      "帮助\n",
      "解决\n",
      "什么\n",
      "问题\n",
      "？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "stream = llm.stream([HumanMessage(content=\"你是谁？你能帮我解决什么问题？\")])\n",
    "for chunk in stream:\n",
    "    print(chunk.text(), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='Translate the following from English into Chinese.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Translate the following from English into {language}.\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\"language\": \"Chinese\", \"text\": \"Hello, how are you?\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，我很好，谢谢。\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0>>极光X9\n",
      "1>>曜科技\n",
      "2>>星耀\n",
      "3>>智星폰\n",
      "4>>Nova X\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    temperature=1.8,\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    response = llm.invoke([HumanMessage(\"给一款智能手机起一个炫酷的名字？返回字数4个汉字以内\")])\n",
    "    print(str(i)+\">>\"+response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
